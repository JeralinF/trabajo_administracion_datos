{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extracción, Almacenamiento y Seguridad de Datos\n",
    "\n",
    "Esta sección es responsable de extraer los datos desde la API de CoinGecko, almacenarlos en un archivo CSV y aplicar medidas de seguridad (encriptación y desencriptación de datos).\n",
    "\n",
    "## Funcionalidades Clave:\n",
    "### Obtención de Información del Usuario e IP:\n",
    "Se utiliza os.getlogin() y socket.gethostbyname() para obtener el nombre de usuario e IP de la máquina.\n",
    "### Carga de Roles y Configuración de Seguridad:\n",
    "Se carga un archivo JSON (config.json) para gestionar roles y se genera una clave de encriptación usando la librería cryptography con Fernet.\n",
    "### Extracción de Datos:\n",
    "Se realiza la llamada a la API de CoinGecko para extraer información sobre criptomonedas y se gestiona la respuesta con manejo de errores y logging.\n",
    "### Almacenamiento de Datos:\n",
    "Los datos extraídos se transforman en un DataFrame de Pandas y se guardan en un archivo CSV (datos_cripto.csv).\n",
    "### Seguridad de Datos:\n",
    "Se implementa la encriptación del archivo CSV y posteriormente se realiza la desencriptación para verificar el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import socket\n",
    "import requests\n",
    "from cryptography.fernet import Fernet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    filename=\"audit_log.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Obtención de usuario e IP del sistema\n",
    "def get_user_info():\n",
    "    user = os.getlogin()\n",
    "    ip = socket.gethostbyname(socket.gethostname())\n",
    "    return user, ip\n",
    "\n",
    "# Carga del JSON para roles\n",
    "def load_roles(config_file=\"config.json\"):\n",
    "    with open(config_file, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "roles = load_roles()\n",
    "\n",
    "# Generar clave de cifrado\n",
    "key = Fernet.generate_key()\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "# Guardar clave de encriptación\n",
    "def save_key(key, filename=\"clave.key\"):\n",
    "    with open(filename, \"wb\") as key_file:\n",
    "        key_file.write(key)\n",
    "    logging.info(\"Clave de encriptación generada y guardada correctamente.\")\n",
    "\n",
    "save_key(key)\n",
    "\n",
    "# Función para verificar permisos\n",
    "def check_access(role):\n",
    "    if role not in roles:\n",
    "        logging.warning(f\"Acceso denegado: Rol {role} no registrado\")\n",
    "        raise PermissionError(\"Acceso denegado: Rol no registrado\")\n",
    "    return roles[role][\"access_level\"]\n",
    "\n",
    "# Extraer datos desde CoinGecko API\n",
    "def extract_data_from_api():\n",
    "    api_url = \"https://api.coingecko.com/api/v3/coins/markets\"\n",
    "    params = {\n",
    "        \"vs_currency\": \"usd\",\n",
    "        \"order\": \"market_cap_desc\",\n",
    "        \"per_page\": 10,\n",
    "        \"page\": 1,\n",
    "        \"sparkline\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        logging.info(\"Datos extraídos exitosamente desde la API.\")\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error al extraer datos de la API: {e}\")\n",
    "        raise\n",
    "\n",
    "# Guardar datos en CSV\n",
    "def save_data_to_csv(data, filename=\"datos_cripto.csv\"):\n",
    "    df = pd.DataFrame([{\n",
    "        \"nombre\": coin[\"name\"],\n",
    "        \"simbolo\": coin[\"symbol\"],\n",
    "        \"precio_usd\": coin[\"current_price\"],\n",
    "        \"cambio_24h\": coin[\"price_change_percentage_24h\"],\n",
    "        \"capitalizacion_mercado\": coin[\"market_cap\"]\n",
    "    } for coin in data])\n",
    "\n",
    "    df.to_csv(filename, index=False)\n",
    "    logging.info(f\"Datos guardados en {filename} correctamente.\")\n",
    "    print(f\"Datos guardados en {filename} correctamente.\")\n",
    "\n",
    "# Encriptar datos\n",
    "def encrypt_file(filename, cipher):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        datos = file.read()\n",
    "    datos_encriptados = cipher.encrypt(datos)\n",
    "\n",
    "    with open(f\"{filename}.enc\", \"wb\") as file:\n",
    "        file.write(datos_encriptados)\n",
    "    logging.info(f\"Datos encriptados y guardados en {filename}.enc correctamente.\")\n",
    "    print(f\"Datos encriptados y guardados en {filename}.enc correctamente.\")\n",
    "\n",
    "# Desencriptar datos\n",
    "def decrypt_file(encrypted_filename, decrypted_filename, cipher):\n",
    "    with open(encrypted_filename, \"rb\") as file:\n",
    "        datos_encriptados = file.read()\n",
    "    datos_desencriptados = cipher.decrypt(datos_encriptados)\n",
    "\n",
    "    with open(decrypted_filename, \"wb\") as file:\n",
    "        file.write(datos_desencriptados)\n",
    "    logging.info(f\"Datos desencriptados y guardados en {decrypted_filename} correctamente.\")\n",
    "    print(f\"Datos desencriptados y guardados en {decrypted_filename} correctamente.\")\n",
    "\n",
    "# Ejecución del pipeline de extracción y seguridad\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data = extract_data_from_api()\n",
    "        save_data_to_csv(data)\n",
    "        encrypt_file(\"datos_cripto.csv\", cipher_suite)\n",
    "        decrypt_file(\"datos_cripto.csv.enc\", \"datos_cripto_desencriptados.csv\", cipher_suite)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en el pipeline: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpieza, Transformación y Modelado de Datos\n",
    "\n",
    "Esta parte se encarga de preparar y transformar los datos extraídos, y de integrar un modelo de IA (SVM en este caso) para predecir el comportamiento del precio de las criptomonedas.\n",
    "\n",
    "## Funcionalidades Clave:\n",
    "### Transformación de Datos:\n",
    "Se convierte el JSON recibido desde la API en un DataFrame y se exporta a CSV, facilitando la limpieza y la transformación de datos (manejo de duplicados, valores faltantes, etc.).\n",
    "### Modelado:\n",
    "Se carga un modelo previamente entrenado (almacenado en svm_model.pkl) y se define una función que realiza la predicción:\n",
    "Se escalonan los datos usando StandardScaler para adecuar la entrada al modelo.\n",
    "Se ejecuta la predicción y se retorna el resultado (subida o bajada del precio).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "def load_model():\n",
    "    # Si has guardado tu modelo en un archivo con joblib, lo puedes cargar aquí\n",
    "    model = joblib.load(\"svm_model.pkl\")\n",
    "    return model\n",
    "\n",
    "# Función para predecir si el precio sube o baja\n",
    "def predict_price_change(precio_usd, cambio_24h, capitalizacion_mercado, model):\n",
    "    data = np.array([[precio_usd, cambio_24h, capitalizacion_mercado]])\n",
    "    # Escalar los datos\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    prediction = model.predict(data_scaled)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Desarrollo de la Aplicación Web y Documentación\n",
    "\n",
    "La aplicación web, desarrollada en Streamlit, integra tanto el pipeline de datos como el modelo de IA. Permite al usuario interactuar de forma visual con los resultados.\n",
    "\n",
    "## Funcionalidades Clave:\n",
    "### Visualización del Data Pipeline:\n",
    "Se muestra un diagrama de flujo (utilizando Graphviz) que representa las etapas: Extracción, Limpieza, Almacenamiento, Procesamiento y Modelado.\n",
    "Se visualizan los logs de procesamiento y se simula la cantidad de registros procesados en cada etapa.\n",
    "### Exploración y Análisis de Datos:\n",
    "Se muestran histogramas para visualizar la distribución de variables clave.\n",
    "Se genera un heatmap para observar las correlaciones entre variables.\n",
    "Se visualizan los porcentajes de valores faltantes mediante un gráfico de barras.\n",
    "Se utilizan boxplots para detectar posibles outliers.\n",
    "### Visualización de Predicciones y Métricas:\n",
    "Se carga un CSV con columnas como actual y predicho para visualizar la matriz de confusión.\n",
    "Se muestra la curva ROC/AUC (si se proveen probabilidades).\n",
    "Se compara visualmente, mediante un gráfico de dispersión, los valores reales y predichos.\n",
    "Se incluye la opción de calcular y visualizar SHAP values para explicar la predicción del modelo.\n",
    "### Interactividad:\n",
    "Permite la carga de nuevos datos a través de la interfaz.\n",
    "Permite la entrada interactiva de datos para realizar predicciones en vivo.\n",
    "Se utiliza Plotly para gráficos interactivos que permiten hacer zoom y desplazarse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import shap\n",
    "\n",
    "# Título de la aplicación web\n",
    "st.title(\"Clasificador de Cambio de Precio de Criptomonedas\")\n",
    "\n",
    "# Sidebar para navegación entre secciones\n",
    "st.sidebar.title(\"Navegación\")\n",
    "page = st.sidebar.radio(\"Selecciona la sección:\", \n",
    "                        [\"Data Pipeline\", \"Exploración y Análisis\", \"Métricas y Predicciones\", \"Predicción en Vivo\", \"Carga de Nuevos Datos\"])\n",
    "\n",
    "#############################\n",
    "# 1. Data Pipeline          #\n",
    "#############################\n",
    "if page == \"Data Pipeline\":\n",
    "    st.header(\"Visualización del Data Pipeline\")\n",
    "    \n",
    "    # Diagrama de flujo usando Graphviz\n",
    "    pipeline_diagram = \"\"\"\n",
    "    digraph {\n",
    "      Extraccion [label=\"Extracción\"];\n",
    "      Limpieza [label=\"Limpieza\"];\n",
    "      Almacenamiento [label=\"Almacenamiento\"];\n",
    "      Procesamiento [label=\"Procesamiento\"];\n",
    "      Modelado [label=\"Modelado\"];\n",
    "      \n",
    "      Extraccion -> Limpieza -> Almacenamiento -> Procesamiento -> Modelado;\n",
    "    }\n",
    "    \"\"\"\n",
    "    st.subheader(\"Diagrama de Flujo\")\n",
    "    st.graphviz_chart(pipeline_diagram)\n",
    "\n",
    "    # Logs de Procesamiento\n",
    "    st.subheader(\"Logs de Procesamiento\")\n",
    "    if os.path.exists(\"audit_log.txt\"):\n",
    "        with open(\"audit_log.txt\", \"r\") as f:\n",
    "            logs = f.read()\n",
    "        st.text_area(\"Contenido de audit_log.txt\", logs, height=200)\n",
    "    else:\n",
    "        st.info(\"No se encontró el archivo de logs.\")\n",
    "\n",
    "    # Simulación de registros procesados en cada etapa\n",
    "    st.subheader(\"Número de Registros Procesados por Etapa\")\n",
    "    try:\n",
    "        df_pipeline = pd.read_csv(\"datos_cripto.csv\")\n",
    "        n_registros = len(df_pipeline)\n",
    "    except Exception:\n",
    "        n_registros = 10\n",
    "\n",
    "    pipeline_data = pd.DataFrame({\n",
    "        \"Etapa\": [\"Extracción\", \"Limpieza\", \"Almacenamiento\", \"Procesamiento\", \"Modelado\"],\n",
    "        \"Registros\": [n_registros, n_registros, n_registros, n_registros, n_registros]\n",
    "    })\n",
    "    st.bar_chart(pipeline_data.set_index(\"Etapa\"))\n",
    "\n",
    "#############################\n",
    "# 2. Exploración y Análisis #\n",
    "#############################\n",
    "elif page == \"Exploración y Análisis\":\n",
    "    st.header(\"Exploración y Análisis de Datos\")\n",
    "    try:\n",
    "        df = pd.read_csv(\"datos_cripto.csv\")\n",
    "        st.success(\"Dataset cargado correctamente.\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error al cargar el dataset: {e}\")\n",
    "        df = None\n",
    "\n",
    "    if df is not None:\n",
    "        st.subheader(\"Distribución de Datos\")\n",
    "        numeric_cols = [\"precio_usd\", \"cambio_24h\", \"capitalizacion_mercado\"]\n",
    "        variable = st.selectbox(\"Selecciona una variable:\", numeric_cols)\n",
    "        fig = px.histogram(df, x=variable, nbins=10, title=f\"Histograma de {variable}\")\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "        st.subheader(\"Correlaciones\")\n",
    "        corr = df[numeric_cols].corr()\n",
    "        fig_corr = px.imshow(corr, text_auto=True, aspect=\"auto\", title=\"Heatmap de Correlaciones\")\n",
    "        st.plotly_chart(fig_corr)\n",
    "\n",
    "        st.subheader(\"Valores Faltantes\")\n",
    "        missing_pct = df.isnull().mean() * 100\n",
    "        missing_df = missing_pct.reset_index()\n",
    "        missing_df.columns = [\"Variable\", \"Porcentaje Faltante\"]\n",
    "        fig_missing = px.bar(missing_df, x=\"Variable\", y=\"Porcentaje Faltante\", title=\"Valores Faltantes (%)\")\n",
    "        st.plotly_chart(fig_missing)\n",
    "\n",
    "        st.subheader(\"Detección de Outliers\")\n",
    "        fig_box = go.Figure()\n",
    "        for col in numeric_cols:\n",
    "            fig_box.add_trace(go.Box(y=df[col], name=col))\n",
    "        fig_box.update_layout(title=\"Boxplots de Variables Numéricas\")\n",
    "        st.plotly_chart(fig_box)\n",
    "\n",
    "#############################\n",
    "# 3. Métricas y Predicciones#\n",
    "#############################\n",
    "elif page == \"Métricas y Predicciones\":\n",
    "    st.header(\"Visualización de Predicciones y Métricas\")\n",
    "    st.markdown(\"**Nota:** Para visualizar estas métricas, carga un archivo CSV con las columnas necesarias (por ejemplo, 'actual' y 'predicho').\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"Sube un CSV con columnas 'actual' y 'predicho'\", type=[\"csv\"])\n",
    "    if uploaded_file is not None:\n",
    "        df_metrics = pd.read_csv(uploaded_file)\n",
    "        st.dataframe(df_metrics.head())\n",
    "\n",
    "        if \"actual\" in df_metrics.columns and \"predicho\" in df_metrics.columns:\n",
    "            st.subheader(\"Matriz de Confusión\")\n",
    "            cm = confusion_matrix(df_metrics[\"actual\"], df_metrics[\"predicho\"])\n",
    "            fig_cm = px.imshow(cm, text_auto=True, \n",
    "                               labels=dict(x=\"Predicción\", y=\"Real\"),\n",
    "                               x=[\"Negativo\", \"Positivo\"], y=[\"Negativo\", \"Positivo\"],\n",
    "                               title=\"Matriz de Confusión\")\n",
    "            st.plotly_chart(fig_cm)\n",
    "\n",
    "            if \"proba\" in df_metrics.columns:\n",
    "                st.subheader(\"Curva ROC/AUC\")\n",
    "                fpr, tpr, thresholds = roc_curve(df_metrics[\"actual\"], df_metrics[\"proba\"])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                fig_roc = go.Figure()\n",
    "                fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='ROC curve'))\n",
    "                fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random', line=dict(dash='dash')))\n",
    "                fig_roc.update_layout(title=f\"Curva ROC (AUC = {roc_auc:.2f})\",\n",
    "                                      xaxis_title=\"Tasa de Falsos Positivos\",\n",
    "                                      yaxis_title=\"Tasa de Verdaderos Positivos\")\n",
    "                st.plotly_chart(fig_roc)\n",
    "            else:\n",
    "                st.info(\"Para la curva ROC/AUC se requiere una columna 'proba' con las probabilidades de predicción.\")\n",
    "\n",
    "            st.subheader(\"Gráfico de Errores (Actual vs Predicho)\")\n",
    "            fig_error = px.scatter(df_metrics, x=\"actual\", y=\"predicho\", trendline=\"ols\",\n",
    "                                   title=\"Comparación entre valores reales y predichos\")\n",
    "            st.plotly_chart(fig_error)\n",
    "        else:\n",
    "            st.error(\"El archivo debe contener las columnas 'actual' y 'predicho'.\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"SHAP Values\")\n",
    "    st.markdown(\"Calcular los valores SHAP para explicar la predicción del modelo (usa solo un subconjunto de datos para evitar tiempos prolongados).\")\n",
    "    if st.button(\"Calcular SHAP\"):\n",
    "        try:\n",
    "            model = load_model()\n",
    "            try:\n",
    "                df_shap = pd.read_csv(\"datos_cripto.csv\")\n",
    "            except Exception:\n",
    "                df_shap = pd.DataFrame({\n",
    "                    \"precio_usd\": [100, 200, 150],\n",
    "                    \"cambio_24h\": [1, -0.5, 0.3],\n",
    "                    \"capitalizacion_mercado\": [1000000, 2000000, 1500000]\n",
    "                })\n",
    "            X_shap = df_shap[[\"precio_usd\", \"cambio_24h\", \"capitalizacion_mercado\"]]\n",
    "            X_sample = X_shap.head(10)\n",
    "            explainer = shap.KernelExplainer(model.predict, X_sample)\n",
    "            shap_values = explainer.shap_values(X_sample)\n",
    "            st.info(\"Generando summary plot de SHAP...\")\n",
    "            fig_shap, ax = plt.subplots()\n",
    "            shap.summary_plot(shap_values, X_sample, show=False)\n",
    "            st.pyplot(fig_shap.figure)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error al calcular SHAP: {e}\")\n",
    "            \n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Importancia de Variables\")\n",
    "    st.markdown(\"Para modelos basados en árboles se puede mostrar la importancia de variables. Dado que este modelo es SVM, la importancia no es nativa.\")\n",
    "    st.info(\"La importancia de variables no se muestra para el modelo SVM actual. Para modelos como Random Forest o XGBoost, se podría calcular usando permutation_importance.\")\n",
    "\n",
    "#############################\n",
    "# 4. Predicción en Vivo     #\n",
    "#############################\n",
    "elif page == \"Predicción en Vivo\":\n",
    "    st.header(\"Clasificador de Cambio de Precio de Criptomonedas\")\n",
    "    st.write(\"Ingresa los valores para predecir si el precio de una criptomoneda subirá o bajará en las próximas 24 horas.\")\n",
    "\n",
    "    precio_usd = st.number_input(\"Precio en USD\", min_value=0.0, value=100.0)\n",
    "    cambio_24h = st.number_input(\"Cambio en 24h (%)\", min_value=-100.0, value=0.0)\n",
    "    capitalizacion_mercado = st.number_input(\"Capitalización de Mercado (en USD)\", min_value=0.0, value=1000000.0)\n",
    "\n",
    "    if st.button(\"Predecir\"):\n",
    "        try:\n",
    "            model = load_model()\n",
    "            prediction = predict_price_change(precio_usd, cambio_24h, capitalizacion_mercado, model)\n",
    "            if prediction == 1:\n",
    "                st.success(\"El precio de la criptomoneda subirá.\")\n",
    "            else:\n",
    "                st.error(\"El precio de la criptomoneda bajará.\")\n",
    "            st.write(\"### Datos de entrada para la predicción:\")\n",
    "            st.write(f\"**Precio en USD:** {precio_usd}\")\n",
    "            st.write(f\"**Cambio en 24h:** {cambio_24h}%\")\n",
    "            st.write(f\"**Capitalización de mercado:** {capitalizacion_mercado} USD\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error al realizar la predicción: {e}\")\n",
    "\n",
    "#############################\n",
    "# 5. Carga de Nuevos Datos  #\n",
    "#############################\n",
    "elif page == \"Carga de Nuevos Datos\":\n",
    "    st.header(\"Carga de Nuevos Datos\")\n",
    "    uploaded_csv = st.file_uploader(\"Sube un archivo CSV\", type=[\"csv\"])\n",
    "    if uploaded_csv is not None:\n",
    "        try:\n",
    "            df_nuevos = pd.read_csv(uploaded_csv)\n",
    "            st.success(\"Archivo cargado exitosamente.\")\n",
    "            st.dataframe(df_nuevos.head())\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error al cargar el archivo: {e}\")\n",
    "    else:\n",
    "        st.info(\"Espera a subir un archivo CSV para visualizar los datos.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
